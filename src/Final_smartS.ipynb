{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Email Categorization by fine tuning BERT model**"
      ],
      "metadata": {
        "id": "XKAc0LUCln1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: ChatGPT is used here for generating training and testing data"
      ],
      "metadata": {
        "id": "4zf20quglSkw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZMfMTrN_ZkR",
        "outputId": "22de7333-ba85-4a9b-b402-6ec5943832bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating training data for finetuning BERT model"
      ],
      "metadata": {
        "id": "fFU8Sf3f_woT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv"
      ],
      "metadata": {
        "id": "jB8GRVFY_7G5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating email data from student to HOD"
      ],
      "metadata": {
        "id": "EU7J5-lP_16e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_email_subjects = [\n",
        "    \"Request for Course Material\",\n",
        "    \"Inquiry About Academic Progress\",\n",
        "    \"Clarification on Assignment\",\n",
        "    \"Extension Request for Submission\",\n",
        "    \"Feedback on Recent Lecture\",\n",
        "    \"Meeting Request for Project Discussion\",\n",
        "    \"Guidance for Exam Preparation\",\n",
        "    \"Syllabus Update Query\",\n",
        "    \"Suggestions for Research Topic\",\n",
        "    \"Request for Office Hours\"\n",
        "]\n",
        "\n",
        "student_email_bodies = [\n",
        "    \"Dear Professor, I hope this message finds you well. I am requesting the lecture notes from last week's class, as I was unable to attend. Your help is appreciated.\",\n",
        "    \"Respected Sir/Madam, Could you kindly update me on my academic standing and current GPA? I would also appreciate advice on how I can improve.\",\n",
        "    \"Hello, I am seeking clarification regarding the machine learning assignment. Could you please specify the format in which you expect the submission?\",\n",
        "    \"Dear Sir, Due to personal circumstances, I am requesting an extension for the project deadline. I apologize for the inconvenience and appreciate your understanding.\",\n",
        "    \"Dear Professor, I wanted to offer some feedback on the last lecture. It was insightful, but the pace was quite fast, and I had difficulty following along.\",\n",
        "    \"Respected Sir/Madam, I would like to arrange a meeting to discuss my final year project and would appreciate your advice on my research direction.\",\n",
        "    \"Dear Sir, With exams approaching, I wanted to ask for your guidance on which topics to focus on and if you could recommend any study materials.\",\n",
        "    \"Hello Professor, I wanted to check if there have been any updates to the syllabus. Could you provide the latest version for reference?\",\n",
        "    \"Dear Professor, I am exploring research topics for my project and was hoping you could suggest some relevant areas in artificial intelligence.\",\n",
        "    \"Respected Sir, I wanted to inquire about your availability during office hours to discuss some questions related to the course content.\"\n",
        "]\n",
        "\n",
        "# Increasing variation in email body by randomizing structure and wording\n",
        "def generate_student_data():\n",
        "    greetings = [\"Dear Professor,\",\n",
        "                 \"Hello Professor,\",\n",
        "                 \"Respected Sir/Madam,\",\n",
        "                 \"Hi, Professor,\",\"Greetings, Professor,\",\n",
        "                 \"Dear Sir,\",\n",
        "                 \"Dear Madam,\"]\n",
        "\n",
        "    ending = [\"Thank you for your time.\",\n",
        "              \"I appreciate your help.\",\n",
        "              \"Looking forward to your reply.\",\n",
        "              \"Thanks in advance for your support.\",\n",
        "              \"Your guidance is much appreciated.\",\n",
        "              \"Thank you for considering my request.\"]\n",
        "\n",
        "    return f\"{random.choice(greetings)} {random.choice(student_email_bodies)} {random.choice(ending)}\"\n",
        "\n",
        "student_email_data = [\n",
        "    {\n",
        "        \"email_address\": f\"student{index}@univeristy.edu\",\n",
        "        \"subject\": random.choice(student_email_subjects),\n",
        "        \"body\": generate_student_data()\n",
        "    }\n",
        "    for index in range(1,101)\n",
        "]\n",
        "\n",
        "csv_file_path_student = \"/content/student_HOD_emails.csv\"\n",
        "\n",
        "with open(csv_file_path_student, mode = 'w', newline = '') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames = ['email_address', 'subject', 'body'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(student_email_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Oka4gpNi_wAb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating email data from corporate to HOD"
      ],
      "metadata": {
        "id": "EgjurwbGFqSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corporate_email_subjects = [\n",
        "    \"Internship Request\",\n",
        "    \"Placement Inquiry\",\n",
        "    \"Follow-up on Job Opportunities\",\n",
        "    \"Request for Placement Details\",\n",
        "    \"Inquiry About Internship Program\",\n",
        "    \"Seeking Corporate Internship\",\n",
        "    \"Placement Status Inquiry\",\n",
        "    \"Request for Job Shadowing\",\n",
        "    \"Application for Internship\",\n",
        "    \"Corporate Internship Details\"\n",
        "]\n",
        "\n",
        "corporate_email_bodies = [\n",
        "    \"Dear Sir/Madam, I hope this message finds you well. I am writing to inquire about available internship opportunities at your company. I would be grateful if you could provide details on the application process.\",\n",
        "    \"Respected Sir/Madam, I would like to express my interest in the upcoming campus placements and request information regarding the companies that will be visiting for recruitment.\",\n",
        "    \"Hello, I am a final year student looking for internship opportunities to gain industry exposure. Could you kindly let me know if there are any openings in your organization?\",\n",
        "    \"Dear Sir/Madam, I recently applied for the internship position at your company and would like to follow up on the status of my application. I look forward to your response.\",\n",
        "    \"Respected Sir/Madam, I wanted to inquire about the corporate internship programs available this summer and whether students from my department would be eligible.\",\n",
        "    \"Dear Sir, I am seeking information on placement opportunities in your esteemed company. Could you please provide details on the requirements and deadlines?\",\n",
        "    \"Hello, I would like to inquire if your company offers job shadowing programs for students looking to gain insights into corporate roles and responsibilities.\",\n",
        "    \"Dear Sir/Madam, I am a final-year student and would like to inquire about internship placements. Could you provide information on available programs and how to apply?\",\n",
        "    \"Greetings, I am interested in an internship at your company to gain experience in the field of software engineering. Could you provide the application guidelines?\",\n",
        "    \"Dear Sir, I would like to request more details on the corporate internship program your company offers. Specifically, I am interested in the eligibility criteria and duration.\"\n",
        "]\n",
        "\n",
        "def generate_corporate_data():\n",
        "  greetings = [\n",
        "      \"Dear Sir/Madam,\",\n",
        "      \"Hello,\",\n",
        "      \"Respected Sir/Madam,\",\n",
        "      \"Greetings,\",\n",
        "      \"Hi, Sir/Madam,\",\n",
        "  ]\n",
        "\n",
        "  ending = [\n",
        "      \"Thank you for your time.\",\n",
        "      \"Looking forward to your response.\",\n",
        "      \"I appreciate your assistance.\",\n",
        "      \"Thanks in advance for your help.\",\n",
        "      \"Your consideration is greatly appreciated.\",\n",
        "  ]\n",
        "\n",
        "  return f\"{random.choice(greetings)} {random.choice(corporate_email_bodies)} {random.choice(ending)}\"\n",
        "\n",
        "corporate_email_data = [\n",
        "    {\n",
        "        \"email_address\": f\"corporate{index}@univeristy.edu\",\n",
        "        \"subject\": random.choice(corporate_email_subjects),\n",
        "        \"body\": generate_corporate_data()\n",
        "    }\n",
        "    for index in range(1,151)\n",
        "]\n",
        "\n",
        "csv_file_path_corporate = \"/content/corporate_HOD_emails.csv\"\n",
        "\n",
        "with open(csv_file_path_corporate, mode = 'w', newline = '') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames = ['email_address', 'subject', 'body'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(corporate_email_data)\n"
      ],
      "metadata": {
        "id": "EVJ8YTFlFu0t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating email data from researcher to HOD"
      ],
      "metadata": {
        "id": "aFrZE6ZfIp_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "researcher_email_subjects = [\n",
        "    \"Request for Shared Research Data\",\n",
        "    \"Inquiry About Research Cooperation\",\n",
        "    \"Request for Research Collaboration\",\n",
        "    \"Inquiry Regarding Research Facilities\",\n",
        "    \"Request for Research Partnership\",\n",
        "    \"Follow-up on Data Sharing Request\",\n",
        "    \"Cooperation Opportunity in Research\",\n",
        "    \"Query About Shared Research Resources\",\n",
        "    \"Collaboration on Research Paper\",\n",
        "    \"Inquiry on Research Facility Usage\"\n",
        "]\n",
        "\n",
        "\n",
        "researcher_email_bodies = [\n",
        "    \"Dear Professor, I hope you are doing well. I am currently working on a project related to artificial intelligence and was hoping to gain access to some of the data your team has worked on. Could you provide information on how to proceed with a data-sharing request?\",\n",
        "    \"Respected Sir/Madam, I am interested in collaborating on research in the field of sustainable energy and would appreciate it if we could explore possible cooperation opportunities. Your expertise would be invaluable.\",\n",
        "    \"Dear Professor, I am currently conducting research in the field of biotechnology and am writing to inquire if we could collaborate on a joint paper. I believe our interests align, and I would love to discuss potential topics.\",\n",
        "    \"Respected Professor, I wanted to inquire about the facilities available at your research lab for conducting experiments in material science. I am looking for specific instruments and would like to know if external researchers are allowed to use them.\",\n",
        "    \"Dear Sir/Madam, I hope this email finds you well. I would like to propose a research partnership on quantum computing and explore avenues where our expertise could complement each other. Could we arrange a meeting?\",\n",
        "    \"Dear Professor, I am following up on my previous request for access to the research data on environmental impact analysis. Could you kindly update me on the status of the data-sharing process?\",\n",
        "    \"Respected Sir/Madam, I am reaching out to inquire if you would be interested in collaborating on research focused on renewable energy sources. I believe we could achieve great results together.\",\n",
        "    \"Dear Professor, I wanted to request access to shared research resources in your lab, specifically in the area of microbiology. Could you guide me on the process for external researchers?\",\n",
        "    \"Respected Professor, I am currently working on a paper on artificial intelligence and wanted to explore if you would be open to collaborating on this research. I believe your insights would add significant value.\",\n",
        "    \"Dear Sir, I am interested in using the advanced facilities at your research center for conducting an experiment on nanotechnology. Could you please provide details on how to gain access as an external researcher?\"\n",
        "]\n",
        "\n",
        "def generate_researcher_data():\n",
        "  greetings = [\n",
        "      \"Dear Professor,\",\n",
        "      \"Hello Professor,\",\n",
        "      \"Respected Professor,\",\n",
        "      \"Hi, Professor,\",\n",
        "      \"Greetings, Professor,\"\n",
        "  ]\n",
        "\n",
        "  ending = [\n",
        "      \"Thank you for considering my request.\",\n",
        "      \"I look forward to your response.\",\n",
        "      \"Your assistance would be greatly appreciated.\",\n",
        "      \"I hope to hear from you soon.\",\n",
        "      \"Thanks in advance for your guidance.\"\n",
        "  ]\n",
        "\n",
        "  return f\"{random.choice(greetings)} {random.choice(researcher_email_bodies)} {random.choice(ending)}\"\n",
        "\n",
        "researcher_email_data = [\n",
        "    {\n",
        "        \"email_address\": f\"researcher{index}@univeristy.edu\",\n",
        "        \"subject\": random.choice(researcher_email_subjects),\n",
        "        \"body\": generate_researcher_data()\n",
        "    }\n",
        "    for index in range(1,151)\n",
        "]\n",
        "\n",
        "csv_file_path_researcher = \"/content/researcher_HOD_emails.csv\"\n",
        "\n",
        "with open(csv_file_path_researcher, mode = 'w', newline = '') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames = ['email_address', 'subject', 'body'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(corporate_email_data)\n"
      ],
      "metadata": {
        "id": "aa2tndVcIugi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning the BERT model"
      ],
      "metadata": {
        "id": "RgpNHDl_J_j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import logging"
      ],
      "metadata": {
        "id": "W6oG2vXuKDUV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppressing warnings from the transformers library\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# Loading the CSV files\n",
        "df_student = pd.read_csv(\"/content/student_HOD_emails.csv\")\n",
        "df_corporate = pd.read_csv(\"/content/corporate_HOD_emails.csv\")\n",
        "df_researcher = pd.read_csv(\"/content/researcher_HOD_emails.csv\")\n",
        "\n",
        "# Adding labels: 0 = student, 1 = corporate, 2 = researcher\n",
        "df_student['label'] = 0\n",
        "df_corporate['label'] = 1\n",
        "df_researcher['label'] = 2\n",
        "\n",
        "# Combining datasets into one dataframe\n",
        "df = pd.concat([df_student,df_corporate,df_researcher])\n",
        "\n",
        "# Shuffling the dataset\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Splitting the dataset into training and testings sets\n",
        "df_train, df_test = train_test_split(df,test_size = 0.2)\n",
        "\n",
        "# Defining the Hugging face for the model access token\n",
        "token = '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'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',use_auth_token = token)\n",
        "\n",
        "# Creating class for Pytorch\n",
        "class EmailDataset(Dataset):\n",
        "  def __init__(self,dataframe,tokenizer,max_len):\n",
        "    self.dataframe = dataframe\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    email = self.dataframe.iloc[index]\n",
        "    subject = email['subject']\n",
        "    body = email['body']\n",
        "    label = email['label']\n",
        "\n",
        "  # Tokenizing the input (concatenate subject and body)\n",
        "    inputs = self.tokenizer(\n",
        "      subject+ \" \" + body,\n",
        "      padding = 'max_length',\n",
        "      truncation = True,\n",
        "      max_length = self.max_len,\n",
        "      return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs['input_ids'].squeeze(0)\n",
        "    attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'label': torch.tensor(label,dtype = torch.long)\n",
        "    }\n",
        "\n",
        "# Defining the parameters\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 8\n",
        "n_EPOCHS = 3\n",
        "ALPHA = 2e-5\n",
        "\n",
        "\n",
        "# Preparing the datasets and dataloaders\n",
        "train_data = EmailDataset(df_train,tokenizer,MAX_LEN)\n",
        "test_data = EmailDataset(df_test,tokenizer,MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False)\n",
        "\n",
        "# Initializing the model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3,use_auth_token = token)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = ALPHA)\n",
        "\n",
        "# Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(n_EPOCHS):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['label'].to(device)\n",
        "\n",
        "    outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f\"Epoch {epoch + 1}/{n_EPOCHS}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "#Evaluation\n",
        "\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['label'].to(device)\n",
        "\n",
        "    outputs = model(input_ids,attention_mask)\n",
        "    logits = outputs.logits\n",
        "    predicts = torch.argmax(logits,dim=1)\n",
        "\n",
        "    all_predictions.extend(predicts.cpu().numpy())\n",
        "    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "# Calculating accuracy\n",
        "acc = accuracy_score(all_labels,all_predictions)\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO8jK7zGKttY",
        "outputId": "5099c8e8-3a53-4a83-c7ed-14ed49dcd6d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2135: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3220: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.9776\n",
            "Epoch 2/3, Loss: 0.5635\n",
            "Epoch 3/3, Loss: 0.5339\n",
            "Test Accuracy: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "yaHgC19fajIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HmHyiYezVnOj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_auth_token=token)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3, use_auth_token=token)\n",
        "\n",
        "# Sample test emails\n",
        "test_emails = [\n",
        "    {\"subject\":\"Inquiry About Course Material\",\"body\":\"Dear HOD, I hope this message finds you well. I would like to know if there are any specific textbooks or resources recommended for the upcoming semester's course. Thank you!\", \"label\": 0},\n",
        "    {\"subject\":\"Internship Opportunity Inquiry\",\"body\":\"Dear HOD, I am reaching out to inquire if your department is open to hosting interns from our university. We are keen on establishing a collaboration. Looking forward to your response.\",\"label\":1},\n",
        "    {\"subject\":\"Collaboration on Research Project\",\"body\":\"Dear HOD, I am a researcher interested in exploring collaboration opportunities with your department. I believe our ongoing projects align well. Could we schedule a meeting to discuss this?\",\"label\":2},\n",
        "    {\"subject\":\"Question About Academic Progress\",\"body\":\"Hello HOD, I hope you are doing well. I wanted to ask about my academic progress and any areas I should focus on to improve. Thank you for your guidance.\",\"label\":0},\n",
        "    {\"subject\":\"Placement Procedure Inquiry\",\"body\":\"Dear HOD, I am writing to ask about the placement procedure for the upcoming semester. Could you please provide the details? Thank you!\",\"label\":1}\n",
        "]\n",
        "\n",
        "# Evaluate the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "actual_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for email in test_emails:\n",
        "        # Prepare input\n",
        "        inputs = tokenizer(email['subject'] + \" \" + email['body'],\n",
        "                           padding='max_length',\n",
        "                           truncation=True,\n",
        "                           max_length=256,\n",
        "                           return_tensors=\"pt\")\n",
        "        input_ids = inputs['input_ids'].to(device)\n",
        "        attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        pred = torch.argmax(logits, dim=1).cpu().item()\n",
        "\n",
        "        # Append predictions and actual labels\n",
        "        predictions.append(pred)\n",
        "        actual_labels.append(email['label'])\n",
        "\n",
        "correct = sum(p==a for p,a in zip(predictions,actual_labels))\n",
        "acc = correct/len(actual_labels)*100\n",
        "print(f\"Test Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# Printing results\n",
        "for email,prediction in zip(test_emails,predictions):\n",
        "  print(f\"Subject: {email['subject']}\\nPredicted Label: {prediction}\\nActual Label: {email['label']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDcwzJOVawZH",
        "outputId": "703b3cce-f177-45db-a852-191c18f0cc49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2135: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3220: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 40.00%\n",
            "Subject: Inquiry About Course Material\n",
            "Predicted Label: 0\n",
            "Actual Label: 0\n",
            "\n",
            "Subject: Internship Opportunity Inquiry\n",
            "Predicted Label: 0\n",
            "Actual Label: 1\n",
            "\n",
            "Subject: Collaboration on Research Project\n",
            "Predicted Label: 0\n",
            "Actual Label: 2\n",
            "\n",
            "Subject: Question About Academic Progress\n",
            "Predicted Label: 0\n",
            "Actual Label: 0\n",
            "\n",
            "Subject: Placement Procedure Inquiry\n",
            "Predicted Label: 0\n",
            "Actual Label: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJoO097ybSdr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}